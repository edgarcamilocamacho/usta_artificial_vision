{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Borra logs anteriores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "shutil.rmtree('logs', ignore_errors=True)\n",
    "shutil.rmtree('logs2', ignore_errors=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importa librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "assert (tf.__version__=='1.15.4'), 'Versión incorrecta de Tensorflow, por favor instale 1.15.4'\n",
    "from tensorflow.contrib.layers import flatten\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset 1\n",
    "\n",
    "Dataset de números del 0 al 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-5-a839aeb82f4b>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /home/camilo/anaconda3/envs/vision/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/camilo/anaconda3/envs/vision/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /home/camilo/anaconda3/envs/vision/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/camilo/anaconda3/envs/vision/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/camilo/anaconda3/envs/vision/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desordena el dataset y lo divide en entrenamiento, validación y prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_, Y_train_ = shuffle(mnist.train.images, mnist.train.labels) \n",
    "X_train_orig, X_val_orig, Y_train, Y_val = train_test_split(X_train_, Y_train_, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.reshape(X_train_orig, (-1, 28, 28))\n",
    "X_val = np.reshape(X_val_orig, (-1, 28, 28))\n",
    "X_test = np.reshape(mnist.test.images, (-1, 28, 28))\n",
    "\n",
    "X_train = np.pad(X_train , ((0,0),(2,2),(2,2)), 'constant')\n",
    "X_val = np.pad(X_val , ((0,0),(2,2),(2,2)), 'constant')\n",
    "X_test = np.pad(X_test , ((0,0),(2,2),(2,2)), 'constant')\n",
    "\n",
    "X_train = X_train[..., np.newaxis]\n",
    "X_val = X_val[..., np.newaxis]\n",
    "X_test = X_test[..., np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (44000, 32, 32, 1), Y_train: (44000, 10)\n",
      "X_val: (11000, 32, 32, 1), Y_val: (11000, 10)\n",
      "X_test: (10000, 32, 32, 1), Y_test: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(f'X_train: {X_train.shape}, Y_train: {Y_train.shape}')\n",
    "print(f'X_val: {X_val.shape}, Y_val: {Y_val.shape}')\n",
    "print(f'X_test: {X_test.shape}, Y_test: {Y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prueba del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f356b3079e8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[15][:,:,0], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lenet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Placeholders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, (None, 32, 32, 1))\n",
    "y = tf.placeholder(tf.int32, (None, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capas ocultas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/camilo/anaconda3/envs/vision/lib/python3.6/site-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From /home/camilo/anaconda3/envs/vision/lib/python3.6/site-packages/tensorflow_core/python/layers/core.py:332: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n"
     ]
    }
   ],
   "source": [
    "n_classes = 10\n",
    "  \n",
    "# Arguments used for tf.truncated_normal, randomly defines variables for the weights and biases for each layer\n",
    "mu = 0\n",
    "sigma = 0.1    \n",
    "\n",
    "weights = {\n",
    "    # The shape of the filter weight is (height, width, input_depth, output_depth)\n",
    "    'conv1': tf.Variable(tf.truncated_normal(shape=(5, 5, 1, 6), mean = mu, stddev = sigma)),\n",
    "    'conv2': tf.Variable(tf.truncated_normal(shape=(5, 5, 6, 16), mean = mu, stddev = sigma)),\n",
    "    'fl1': tf.Variable(tf.truncated_normal(shape=(5 * 5 * 16, 120), mean = mu, stddev = sigma)),\n",
    "    'fl2': tf.Variable(tf.truncated_normal(shape=(120, 84), mean = mu, stddev = sigma)),\n",
    "    'out': tf.Variable(tf.truncated_normal(shape=(84, n_classes), mean = mu, stddev = sigma))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    # The shape of the filter bias is (output_depth,)\n",
    "    'conv1': tf.Variable(tf.zeros(6)),\n",
    "    'conv2': tf.Variable(tf.zeros(16)),\n",
    "    'fl1': tf.Variable(tf.zeros(120)),\n",
    "    'fl2': tf.Variable(tf.zeros(84)),\n",
    "    'out': tf.Variable(tf.zeros(n_classes))\n",
    "}\n",
    "\n",
    "# Layer 1: Convolutional. Input = 32x32x1. Output = 28x28x6.\n",
    "conv1 = tf.nn.conv2d(x, weights['conv1'], strides=[1, 1, 1, 1], padding='VALID')\n",
    "conv1 = tf.nn.bias_add(conv1, biases['conv1'])\n",
    "# Activation.\n",
    "conv1 = tf.nn.relu(conv1)\n",
    "# Pooling. Input = 28x28x6. Output = 14x14x6.\n",
    "conv1 = tf.nn.avg_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "\n",
    "# Layer 2: Convolutional. Output = 10x10x16.\n",
    "conv2 = tf.nn.conv2d(conv1, weights['conv2'], strides=[1, 1, 1, 1], padding='VALID')\n",
    "conv2 = tf.nn.bias_add(conv2, biases['conv2'])\n",
    "# Activation.\n",
    "conv2 = tf.nn.relu(conv2)\n",
    "# Pooling. Input = 10x10x16. Output = 5x5x16.\n",
    "conv2 = tf.nn.avg_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "\n",
    "# Flatten. Input = 5x5x16. Output = 400.\n",
    "fl0 = flatten(conv2)\n",
    "\n",
    "# Layer 3: Fully Connected. Input = 400. Output = 120.\n",
    "fl1 = tf.add(tf.matmul(fl0, weights['fl1']), biases['fl1'])\n",
    "# Activation.\n",
    "fl1 = tf.nn.relu(fl1)\n",
    "\n",
    "# Layer 4: Fully Connected. Input = 120. Output = 84.\n",
    "fl2 = tf.add(tf.matmul(fl1, weights['fl2']), biases['fl2'])\n",
    "# Activation.\n",
    "fl2 = tf.nn.relu(fl2)\n",
    "\n",
    "# Layer 5: Fully Connected. Input = 84. Output = 10.\n",
    "logits = tf.add(tf.matmul(fl2, weights['out']), biases['out'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pérdida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-13-fc6d1f807428>:1: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y)\n",
    "loss_operation = tf.reduce_mean(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Métricas para Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries = [\n",
    "    tf.summary.histogram(\"weights/conv1\", weights['conv1']),\n",
    "    tf.summary.histogram(\"weights/conv2\", weights['conv2']),\n",
    "    tf.summary.histogram(\"weights/fl1\", weights['fl1']),\n",
    "    tf.summary.histogram(\"weights/fl2\", weights['fl2']),\n",
    "    tf.summary.histogram(\"weights/out\", weights['out']),\n",
    "    tf.summary.histogram(\"biases/conv1\", biases['conv1']),\n",
    "    tf.summary.histogram(\"biases/conv2\", biases['conv2']),\n",
    "    tf.summary.histogram(\"biases/fl1\", biases['fl1']),\n",
    "    tf.summary.histogram(\"biases/fl2\", biases['fl2']),\n",
    "    tf.summary.histogram(\"biases/conv1\", biases['out']),\n",
    "    tf.summary.scalar('loss', loss_operation),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cálculo de precisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "accuracy_summary = tf.summary.scalar('accuracy', accuracy_operation)\n",
    "\n",
    "def evaluate(X_data, y_data):\n",
    "    num_examples = len(X_data)\n",
    "    total_accuracy = 0\n",
    "    sess = tf.get_default_session()\n",
    "    for offset in range(0, num_examples, BATCH_SIZE):\n",
    "        batch_x, batch_y = X_data[offset:offset+BATCH_SIZE], y_data[offset:offset+BATCH_SIZE]\n",
    "        accuracy, summ = sess.run([accuracy_operation, accuracy_summary], feed_dict={x: batch_x, y: batch_y})\n",
    "        total_accuracy += (accuracy * len(batch_x))\n",
    "        \n",
    "    return total_accuracy / num_examples, summ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento del dataset de 0 a 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todas las variables se modifican en la optimización, para el primer entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_to_opt = [ weights['conv1'], weights['conv2'], weights['fl1'], weights['fl2'], weights['out'], \n",
    "                biases['conv1'], biases['conv2'], biases['fl1'], biases['fl2'], biases['out'] ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate)\n",
    "training_operation = optimizer.minimize(loss_operation, var_list=vars_to_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LeNet...\n",
      "\n",
      "EPOCH 1 ...\n",
      "Validation Accuracy = 0.947\n",
      "\n",
      "EPOCH 2 ...\n",
      "Validation Accuracy = 0.968\n",
      "\n",
      "EPOCH 3 ...\n",
      "Validation Accuracy = 0.970\n",
      "\n",
      "EPOCH 4 ...\n",
      "Validation Accuracy = 0.975\n",
      "\n",
      "EPOCH 5 ...\n",
      "Validation Accuracy = 0.979\n",
      "\n",
      "EPOCH 6 ...\n",
      "Validation Accuracy = 0.981\n",
      "\n",
      "EPOCH 7 ...\n",
      "Validation Accuracy = 0.982\n",
      "\n",
      "EPOCH 8 ...\n",
      "Validation Accuracy = 0.984\n",
      "\n",
      "EPOCH 9 ...\n",
      "Validation Accuracy = 0.984\n",
      "\n",
      "EPOCH 10 ...\n",
      "Validation Accuracy = 0.982\n",
      "\n",
      "Model saved\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    writer = tf.summary.FileWriter(\"./logs\", session.graph)\n",
    "    \n",
    "    session.run(tf.global_variables_initializer())\n",
    "    num_examples = len(X_train)\n",
    "    \n",
    "    step = 0\n",
    "    \n",
    "    print(\"Training LeNet...\")\n",
    "    print()\n",
    "    for i in range(EPOCHS):\n",
    "        X_train_epoch, Y_train_epoch = shuffle(X_train, Y_train)\n",
    "        for offset in range(0, num_examples, BATCH_SIZE):\n",
    "            end = offset + BATCH_SIZE\n",
    "            batch_x, batch_y = X_train_epoch[offset:end], Y_train_epoch[offset:end]\n",
    "            summs = session.run([training_operation]+summaries, feed_dict={x: batch_x, y: batch_y})\n",
    "            summs.pop(0)\n",
    "            for summ in summs:\n",
    "                writer.add_summary(summ, global_step=step)\n",
    "            step += 1\n",
    "            \n",
    "        validation_accuracy, validation_summary = evaluate(X_val, Y_val)\n",
    "        writer.add_summary(validation_summary, global_step=step)\n",
    "        print(\"EPOCH {} ...\".format(i+1))\n",
    "        print(\"Validation Accuracy = {:.3f}\".format(validation_accuracy))\n",
    "        print()\n",
    "    \n",
    "    writer.close()\n",
    "    \n",
    "    saver.save(session, './models/lenet/lenet')\n",
    "    print(\"Model saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba del dataset de 0 a 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models/lenet/lenet\n",
      "Test Accuracy = 0.984\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    saver.restore(session, tf.train.latest_checkpoint('./models/lenet'))\n",
    "\n",
    "    test_accuracy, _ = evaluate(X_test, Y_test)\n",
    "    print(\"Test Accuracy = {:.3f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset de letras de la A a la J\n",
    "EMNIST es MNIST extendido, tiene letras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: emnist in /home/camilo/anaconda3/envs/vision/lib/python3.6/site-packages (0.0)\n",
      "Requirement already satisfied: tqdm in /home/camilo/.local/lib/python3.6/site-packages (from emnist) (4.46.0)\n",
      "Requirement already satisfied: requests in /home/camilo/.local/lib/python3.6/site-packages (from emnist) (2.23.0)\n",
      "Requirement already satisfied: numpy in /home/camilo/anaconda3/envs/vision/lib/python3.6/site-packages (from emnist) (1.18.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/camilo/anaconda3/envs/vision/lib/python3.6/site-packages (from requests->emnist) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/camilo/.local/lib/python3.6/site-packages (from requests->emnist) (2.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/camilo/.local/lib/python3.6/site-packages (from requests->emnist) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/camilo/.local/lib/python3.6/site-packages (from requests->emnist) (1.25.9)\n"
     ]
    }
   ],
   "source": [
    "! pip install emnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from emnist import extract_training_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La primera vez, se demora descargando el dataset (aproximadamente 536MB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_orig, Y_orig_idx = extract_training_samples('letters')\n",
    "A_J_ixd = Y_orig_idx<=10\n",
    "\n",
    "X_orig = X_orig[A_J_ixd]\n",
    "X_orig = np.pad(X_orig , ((0,0),(2,2),(2,2)), 'constant')\n",
    "X_orig = X_orig[..., np.newaxis]\n",
    "X_orig = X_orig / 255.0\n",
    "\n",
    "Y_orig_idx = Y_orig_idx[A_J_ixd] - 1\n",
    "Y_orig = np.zeros((Y_orig_idx.size, Y_orig_idx.max()+1))\n",
    "Y_orig[np.arange(Y_orig_idx.size),Y_orig_idx] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_orig: (48000, 32, 32, 1), Y_orig: (48000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(f'X_orig: {X_orig.shape}, Y_orig: {Y_orig.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class: 2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 582\n",
    "plt.imshow(X_orig[idx][:,:,0], cmap='gray')\n",
    "print(f'class: {Y_orig_idx[idx]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (30720, 32, 32, 1), Y_train: (30720, 10)\n",
      "X_val: (7680, 32, 32, 1), Y_val: (7680, 10)\n",
      "X_test: (9600, 32, 32, 1), Y_test: (9600, 10)\n"
     ]
    }
   ],
   "source": [
    "X_orig, Y_orig = shuffle(X_orig, Y_orig) \n",
    "X_orig_, X_test, Y_orig_, Y_test = train_test_split(X_orig, Y_orig, test_size=0.2)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_orig_, Y_orig_, test_size=0.2)\n",
    "\n",
    "print(f'X_train: {X_train.shape}, Y_train: {Y_train.shape}')\n",
    "print(f'X_val: {X_val.shape}, Y_val: {Y_val.shape}')\n",
    "print(f'X_test: {X_test.shape}, Y_test: {Y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probando dataset de letras con entrenamiento de números"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models/lenet/lenet\n",
      "Test Accuracy = 0.094\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    saver.restore(session, tf.train.latest_checkpoint('./models/lenet'))\n",
    "\n",
    "    test_accuracy, _ = evaluate(X_test, Y_test)\n",
    "    print(\"Test Accuracy = {:.3f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizador para entrenamiento de letras\n",
    "\n",
    "No se tocan las capas convolucionales, únicamente se modifican las fully connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_to_opt_2 = [ weights['fl1'], weights['fl2'], weights['out'], \n",
    "                 biases['fl1'], biases['fl2'], biases['out'] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "optimizer_2 = tf.train.AdamOptimizer(learning_rate = learning_rate)\n",
    "training_operation_2 = optimizer_2.minimize(loss_operation, var_list=vars_to_opt_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento para letras de A a J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 5\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models/lenet/lenet\n",
      "Training LeNet 2...\n",
      "\n",
      "EPOCH 1 ...\n",
      "Validation Accuracy = 0.909\n",
      "\n",
      "EPOCH 2 ...\n",
      "Validation Accuracy = 0.940\n",
      "\n",
      "EPOCH 3 ...\n",
      "Validation Accuracy = 0.949\n",
      "\n",
      "EPOCH 4 ...\n",
      "Validation Accuracy = 0.958\n",
      "\n",
      "EPOCH 5 ...\n",
      "Validation Accuracy = 0.958\n",
      "\n",
      "Model saved\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    saver.restore(session, tf.train.latest_checkpoint('./models/lenet'))\n",
    "    \n",
    "    writer = tf.summary.FileWriter(\"./logs2\", session.graph)\n",
    "    \n",
    "    num_examples = len(X_train)\n",
    "    \n",
    "    step = 0\n",
    "    \n",
    "    print(\"Training LeNet 2...\")\n",
    "    print()\n",
    "    for i in range(EPOCHS):\n",
    "        X_train_epoch, Y_train_epoch = shuffle(X_train, Y_train)\n",
    "        for offset in range(0, num_examples, BATCH_SIZE):\n",
    "            end = offset + BATCH_SIZE\n",
    "            batch_x, batch_y = X_train_epoch[offset:end], Y_train_epoch[offset:end]\n",
    "            summs = session.run([training_operation_2]+summaries, feed_dict={x: batch_x, y: batch_y})\n",
    "            summs.pop(0)\n",
    "            for summ in summs:\n",
    "                writer.add_summary(summ, global_step=step)\n",
    "            step += 1\n",
    "            \n",
    "        validation_accuracy, validation_summary = evaluate(X_val, Y_val)\n",
    "        writer.add_summary(validation_summary, global_step=step)\n",
    "        print(\"EPOCH {} ...\".format(i+1))\n",
    "        print(\"Validation Accuracy = {:.3f}\".format(validation_accuracy))\n",
    "        print()\n",
    "    \n",
    "    writer.close()\n",
    "    \n",
    "    saver.save(session, './models/lenet2/lenet2')\n",
    "    print(\"Model saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba para letras de A a J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models/lenet2/lenet2\n",
      "Test Accuracy = 0.954\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    saver.restore(session, tf.train.latest_checkpoint('./models/lenet2'))\n",
    "\n",
    "    test_accuracy, _ = evaluate(X_test, Y_test)\n",
    "    print(\"Test Accuracy = {:.3f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
