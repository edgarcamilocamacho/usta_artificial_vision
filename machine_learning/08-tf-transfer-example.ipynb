{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Borra logs anteriores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "shutil.rmtree('logs', ignore_errors=True)\n",
    "shutil.rmtree('logs2', ignore_errors=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importa librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "assert (tf.__version__=='1.15.4'), 'Versión incorrecta de Tensorflow, por favor instale 1.15.4'\n",
    "from tensorflow.contrib.layers import flatten\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset 1\n",
    "\n",
    "Dataset de números del 0 al 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-5-4a0c05dcd5b2>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /home/camilo/anaconda3/envs/vision/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/camilo/anaconda3/envs/vision/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /home/camilo/anaconda3/envs/vision/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/camilo/anaconda3/envs/vision/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting /tmp/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/camilo/anaconda3/envs/vision/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"/tmp/MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desordena el dataset y lo divide en entrenamiento, validación y prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_, Y_train_ = shuffle(mnist.train.images, mnist.train.labels) \n",
    "X_train_orig, X_val_orig, Y_train, Y_val = train_test_split(X_train_, Y_train_, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.reshape(X_train_orig, (-1, 28, 28))\n",
    "X_val = np.reshape(X_val_orig, (-1, 28, 28))\n",
    "X_test = np.reshape(mnist.test.images, (-1, 28, 28))\n",
    "\n",
    "X_train = np.pad(X_train , ((0,0),(2,2),(2,2)), 'constant')\n",
    "X_val = np.pad(X_val , ((0,0),(2,2),(2,2)), 'constant')\n",
    "X_test = np.pad(X_test , ((0,0),(2,2),(2,2)), 'constant')\n",
    "\n",
    "X_train = X_train[..., np.newaxis]\n",
    "X_val = X_val[..., np.newaxis]\n",
    "X_test = X_test[..., np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (44000, 32, 32, 1), Y_train: (44000, 10)\n",
      "X_val: (11000, 32, 32, 1), Y_val: (11000, 10)\n",
      "X_test: (10000, 32, 32, 1), Y_test: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(f'X_train: {X_train.shape}, Y_train: {Y_train.shape}')\n",
    "print(f'X_val: {X_val.shape}, Y_val: {Y_val.shape}')\n",
    "print(f'X_test: {X_test.shape}, Y_test: {Y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prueba del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f57a9585780>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[15][:,:,0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train[15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lenet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Placeholders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, (None, 32, 32, 1))\n",
    "y = tf.placeholder(tf.int32, (None, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capas ocultas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/camilo/anaconda3/envs/vision/lib/python3.6/site-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From /home/camilo/anaconda3/envs/vision/lib/python3.6/site-packages/tensorflow_core/python/layers/core.py:332: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n"
     ]
    }
   ],
   "source": [
    "n_classes = 10\n",
    "  \n",
    "# Arguments used for tf.truncated_normal, randomly defines variables for the weights and biases for each layer\n",
    "mu = 0\n",
    "sigma = 0.1    \n",
    "\n",
    "weights = {\n",
    "    # The shape of the filter weight is (height, width, input_depth, output_depth)\n",
    "    'conv1': tf.Variable(tf.truncated_normal(shape=(5, 5, 1, 6), mean = mu, stddev = sigma)),\n",
    "    'conv2': tf.Variable(tf.truncated_normal(shape=(5, 5, 6, 16), mean = mu, stddev = sigma)),\n",
    "    'fl1': tf.Variable(tf.truncated_normal(shape=(5 * 5 * 16, 120), mean = mu, stddev = sigma)),\n",
    "    'fl2': tf.Variable(tf.truncated_normal(shape=(120, 84), mean = mu, stddev = sigma)),\n",
    "    'out': tf.Variable(tf.truncated_normal(shape=(84, n_classes), mean = mu, stddev = sigma))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    # The shape of the filter bias is (output_depth,)\n",
    "    'conv1': tf.Variable(tf.zeros(6)),\n",
    "    'conv2': tf.Variable(tf.zeros(16)),\n",
    "    'fl1': tf.Variable(tf.zeros(120)),\n",
    "    'fl2': tf.Variable(tf.zeros(84)),\n",
    "    'out': tf.Variable(tf.zeros(n_classes))\n",
    "}\n",
    "\n",
    "# Layer 1: Convolutional. Input = 32x32x1. Output = 28x28x6.\n",
    "conv1 = tf.nn.conv2d(x, weights['conv1'], strides=[1, 1, 1, 1], padding='VALID')\n",
    "conv1 = tf.nn.bias_add(conv1, biases['conv1'])\n",
    "# Activation.\n",
    "conv1 = tf.nn.relu(conv1)\n",
    "# Pooling. Input = 28x28x6. Output = 14x14x6.\n",
    "conv1 = tf.nn.avg_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "\n",
    "# Layer 2: Convolutional. Output = 10x10x16.\n",
    "conv2 = tf.nn.conv2d(conv1, weights['conv2'], strides=[1, 1, 1, 1], padding='VALID')\n",
    "conv2 = tf.nn.bias_add(conv2, biases['conv2'])\n",
    "# Activation.\n",
    "conv2 = tf.nn.relu(conv2)\n",
    "# Pooling. Input = 10x10x16. Output = 5x5x16.\n",
    "conv2 = tf.nn.avg_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "\n",
    "# Flatten. Input = 5x5x16. Output = 400.\n",
    "fl0 = flatten(conv2)\n",
    "\n",
    "# Layer 3: Fully Connected. Input = 400. Output = 120.\n",
    "fl1 = tf.add(tf.matmul(fl0, weights['fl1']), biases['fl1'])\n",
    "# Activation.\n",
    "fl1 = tf.nn.relu(fl1)\n",
    "\n",
    "# Layer 4: Fully Connected. Input = 120. Output = 84.\n",
    "fl2 = tf.add(tf.matmul(fl1, weights['fl2']), biases['fl2'])\n",
    "# Activation.\n",
    "fl2 = tf.nn.relu(fl2)\n",
    "\n",
    "# Layer 5: Fully Connected. Input = 84. Output = 10.\n",
    "logits = tf.add(tf.matmul(fl2, weights['out']), biases['out'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pérdida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-21-fc6d1f807428>:1: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y)\n",
    "loss_operation = tf.reduce_mean(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Métricas para Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries = [\n",
    "    tf.summary.histogram(\"weights/conv1\", weights['conv1']),\n",
    "    tf.summary.histogram(\"weights/conv2\", weights['conv2']),\n",
    "    tf.summary.histogram(\"weights/fl1\", weights['fl1']),\n",
    "    tf.summary.histogram(\"weights/fl2\", weights['fl2']),\n",
    "    tf.summary.histogram(\"weights/out\", weights['out']),\n",
    "    tf.summary.histogram(\"biases/conv1\", biases['conv1']),\n",
    "    tf.summary.histogram(\"biases/conv2\", biases['conv2']),\n",
    "    tf.summary.histogram(\"biases/fl1\", biases['fl1']),\n",
    "    tf.summary.histogram(\"biases/fl2\", biases['fl2']),\n",
    "    tf.summary.histogram(\"biases/conv1\", biases['out']),\n",
    "    tf.summary.scalar('loss', loss_operation),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cálculo de precisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "accuracy_summary = tf.summary.scalar('accuracy', accuracy_operation)\n",
    "\n",
    "def evaluate(X_data, y_data):\n",
    "    num_examples = len(X_data)\n",
    "    total_accuracy = 0\n",
    "    sess = tf.get_default_session()\n",
    "    for offset in range(0, num_examples, BATCH_SIZE):\n",
    "        batch_x, batch_y = X_data[offset:offset+BATCH_SIZE], y_data[offset:offset+BATCH_SIZE]\n",
    "        accuracy, summ = sess.run([accuracy_operation, accuracy_summary], feed_dict={x: batch_x, y: batch_y})\n",
    "        total_accuracy += (accuracy * len(batch_x))\n",
    "        \n",
    "    return total_accuracy / num_examples, summ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento del dataset de 0 a 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todas las variables se modifican en la optimización, para el primer entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_to_opt = [ weights['conv1'], weights['conv2'], weights['fl1'], weights['fl2'], weights['out'], \n",
    "                biases['conv1'], biases['conv2'], biases['fl1'], biases['fl2'], biases['out'] ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate)\n",
    "training_operation = optimizer.minimize(loss_operation, var_list=vars_to_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LeNet...\n",
      "\n",
      "EPOCH 1 ...\n",
      "Validation Accuracy = 0.947\n",
      "\n",
      "EPOCH 2 ...\n",
      "Validation Accuracy = 0.968\n",
      "\n",
      "EPOCH 3 ...\n",
      "Validation Accuracy = 0.972\n",
      "\n",
      "EPOCH 4 ...\n",
      "Validation Accuracy = 0.976\n",
      "\n",
      "EPOCH 5 ...\n",
      "Validation Accuracy = 0.976\n",
      "\n",
      "EPOCH 6 ...\n",
      "Validation Accuracy = 0.976\n",
      "\n",
      "EPOCH 7 ...\n",
      "Validation Accuracy = 0.984\n",
      "\n",
      "EPOCH 8 ...\n",
      "Validation Accuracy = 0.985\n",
      "\n",
      "EPOCH 9 ...\n",
      "Validation Accuracy = 0.981\n",
      "\n",
      "EPOCH 10 ...\n",
      "Validation Accuracy = 0.985\n",
      "\n",
      "Model saved\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    writer = tf.summary.FileWriter(\"./logs\", session.graph)\n",
    "    \n",
    "    session.run(tf.global_variables_initializer())\n",
    "    num_examples = len(X_train)\n",
    "    \n",
    "    step = 0\n",
    "    \n",
    "    print(\"Training LeNet...\")\n",
    "    print()\n",
    "    for i in range(EPOCHS):\n",
    "        X_train_epoch, Y_train_epoch = shuffle(X_train, Y_train)\n",
    "        for offset in range(0, num_examples, BATCH_SIZE):\n",
    "            end = offset + BATCH_SIZE\n",
    "            batch_x, batch_y = X_train_epoch[offset:end], Y_train_epoch[offset:end]\n",
    "            summs = session.run([training_operation]+summaries, feed_dict={x: batch_x, y: batch_y})\n",
    "            summs.pop(0)\n",
    "            for summ in summs:\n",
    "                writer.add_summary(summ, global_step=step)\n",
    "            step += 1\n",
    "            \n",
    "        validation_accuracy, validation_summary = evaluate(X_val, Y_val)\n",
    "        writer.add_summary(validation_summary, global_step=step)\n",
    "        print(\"EPOCH {} ...\".format(i+1))\n",
    "        print(\"Validation Accuracy = {:.3f}\".format(validation_accuracy))\n",
    "        print()\n",
    "    \n",
    "    writer.close()\n",
    "    \n",
    "    saver.save(session, './models/lenet/lenet')\n",
    "    print(\"Model saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba del dataset de 0 a 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models/lenet/lenet\n",
      "Test Accuracy = 0.987\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    saver.restore(session, tf.train.latest_checkpoint('./models/lenet'))\n",
    "\n",
    "    test_accuracy, _ = evaluate(X_test, Y_test)\n",
    "    print(\"Test Accuracy = {:.3f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset de letras de la A a la J\n",
    "EMNIST es MNIST extendido, tiene letras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: emnist in /home/camilo/anaconda3/envs/vision/lib/python3.6/site-packages (0.0)\n",
      "Requirement already satisfied: tqdm in /home/camilo/.local/lib/python3.6/site-packages (from emnist) (4.46.0)\n",
      "Requirement already satisfied: numpy in /home/camilo/anaconda3/envs/vision/lib/python3.6/site-packages (from emnist) (1.18.5)\n",
      "Requirement already satisfied: requests in /home/camilo/.local/lib/python3.6/site-packages (from emnist) (2.23.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/camilo/.local/lib/python3.6/site-packages (from requests->emnist) (1.25.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/camilo/.local/lib/python3.6/site-packages (from requests->emnist) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/camilo/.local/lib/python3.6/site-packages (from requests->emnist) (2.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/camilo/anaconda3/envs/vision/lib/python3.6/site-packages (from requests->emnist) (2020.6.20)\n"
     ]
    }
   ],
   "source": [
    "! pip install emnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from emnist import extract_training_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La primera vez, se demora descargando el dataset (aproximadamente 536MB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_orig, Y_orig_idx = extract_training_samples('letters')\n",
    "A_J_ixd = Y_orig_idx<=10\n",
    "\n",
    "X_orig = X_orig[A_J_ixd]\n",
    "X_orig = np.pad(X_orig , ((0,0),(2,2),(2,2)), 'constant')\n",
    "X_orig = X_orig[..., np.newaxis]\n",
    "X_orig = X_orig / 255.0\n",
    "\n",
    "Y_orig_idx = Y_orig_idx[A_J_ixd] - 1\n",
    "Y_orig = np.zeros((Y_orig_idx.size, Y_orig_idx.max()+1))\n",
    "Y_orig[np.arange(Y_orig_idx.size),Y_orig_idx] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_orig: (48000, 32, 32, 1), Y_orig: (48000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(f'X_orig: {X_orig.shape}, Y_orig: {Y_orig.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class: 2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 582\n",
    "plt.imshow(X_orig[idx][:,:,0], cmap='gray')\n",
    "print(f'class: {Y_orig_idx[idx]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (30720, 32, 32, 1), Y_train: (30720, 10)\n",
      "X_val: (7680, 32, 32, 1), Y_val: (7680, 10)\n",
      "X_test: (9600, 32, 32, 1), Y_test: (9600, 10)\n"
     ]
    }
   ],
   "source": [
    "X_orig, Y_orig = shuffle(X_orig, Y_orig) \n",
    "X_orig_, X_test, Y_orig_, Y_test = train_test_split(X_orig, Y_orig, test_size=0.2)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_orig_, Y_orig_, test_size=0.2)\n",
    "\n",
    "print(f'X_train: {X_train.shape}, Y_train: {Y_train.shape}')\n",
    "print(f'X_val: {X_val.shape}, Y_val: {Y_val.shape}')\n",
    "print(f'X_test: {X_test.shape}, Y_test: {Y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probando dataset de letras con entrenamiento de números"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models/lenet/lenet\n",
      "Test Accuracy = 0.070\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    saver.restore(session, tf.train.latest_checkpoint('./models/lenet'))\n",
    "\n",
    "    test_accuracy, _ = evaluate(X_test, Y_test)\n",
    "    print(\"Test Accuracy = {:.3f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizador para entrenamiento de letras\n",
    "\n",
    "No se tocan las capas convolucionales, únicamente se modifican las fully connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_to_opt_2 = [ weights['fl1'], weights['fl2'], weights['out'], \n",
    "                 biases['fl1'], biases['fl2'], biases['out'] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "optimizer_2 = tf.train.AdamOptimizer(learning_rate = learning_rate)\n",
    "training_operation_2 = optimizer_2.minimize(loss_operation, var_list=vars_to_opt_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento para letras de A a J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 5\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models/lenet/lenet\n",
      "Training LeNet 2...\n",
      "\n",
      "EPOCH 1 ...\n",
      "Validation Accuracy = 0.901\n",
      "\n",
      "EPOCH 2 ...\n",
      "Validation Accuracy = 0.931\n",
      "\n",
      "EPOCH 3 ...\n",
      "Validation Accuracy = 0.941\n",
      "\n",
      "EPOCH 4 ...\n",
      "Validation Accuracy = 0.948\n",
      "\n",
      "EPOCH 5 ...\n",
      "Validation Accuracy = 0.953\n",
      "\n",
      "Model saved\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    saver.restore(session, tf.train.latest_checkpoint('./models/lenet'))\n",
    "    \n",
    "    writer = tf.summary.FileWriter(\"./logs2\", session.graph)\n",
    "    \n",
    "    num_examples = len(X_train)\n",
    "    \n",
    "    step = 0\n",
    "    \n",
    "    print(\"Training LeNet 2...\")\n",
    "    print()\n",
    "    for i in range(EPOCHS):\n",
    "        X_train_epoch, Y_train_epoch = shuffle(X_train, Y_train)\n",
    "        for offset in range(0, num_examples, BATCH_SIZE):\n",
    "            end = offset + BATCH_SIZE\n",
    "            batch_x, batch_y = X_train_epoch[offset:end], Y_train_epoch[offset:end]\n",
    "            summs = session.run([training_operation_2]+summaries, feed_dict={x: batch_x, y: batch_y})\n",
    "            summs.pop(0)\n",
    "            for summ in summs:\n",
    "                writer.add_summary(summ, global_step=step)\n",
    "            step += 1\n",
    "            \n",
    "        validation_accuracy, validation_summary = evaluate(X_val, Y_val)\n",
    "        writer.add_summary(validation_summary, global_step=step)\n",
    "        print(\"EPOCH {} ...\".format(i+1))\n",
    "        print(\"Validation Accuracy = {:.3f}\".format(validation_accuracy))\n",
    "        print()\n",
    "    \n",
    "    writer.close()\n",
    "    \n",
    "    saver.save(session, './models/lenet2/lenet2')\n",
    "    print(\"Model saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba para letras de A a J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models/lenet2/lenet2\n",
      "Test Accuracy = 0.951\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    saver.restore(session, tf.train.latest_checkpoint('./models/lenet2'))\n",
    "\n",
    "    test_accuracy, _ = evaluate(X_test, Y_test)\n",
    "    print(\"Test Accuracy = {:.3f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
